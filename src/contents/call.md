---
layout: ../layouts/ContentLayout.astro
title: "Call for Papers"
---
<style>
  h2, h3 {
    scroll-margin-top: 80px; /* Adjust this value based on your header height */
  }
</style>



# Call for Papers

We invite submissions to the Symposium on Probabilistic Machine Learning (ProbML 2026), July 5, 2026 in Seoul (co-located with ICML 2026), and welcome full paper submissions and extended abstracts on the development, analysis, or application of probabilistic methods in AI.

We are delighted to offer three paper tracks:

1. An **archival proceedings track**, where full research papers will be subjected to a rigorous peer review and published in the proceedings of the symposium under the title Symposium in Probabilistic Machine Learning 2026, hosted by the Proceedings of Machine Learning Research (PMLR). 
2. A **non-archival workshop track**.
3. A **fast track** for papers recently accepted elsewhere.

Across all three tracks, we encourage contributions in **two primary areas of focus**. We summarize these areas of focus here, see [in-depth explanation](#areas-of-focus) below.

**Area 1: Probabilistic and/or Bayesian ML Methods.** We encourage submissions that focus on advancing the foundations of:

- probabilistic machine learning,
- probabilistic and (approximate) Bayesian inference,
- Bayesian statistics, and
- decision-making under uncertainty.

ProbML 2026 also welcomes submissions that explore connections between those aforementioned topics and other fields, such as:

- deep learning,
- natural language processing,
- active learning,
- reinforcement learning,
- compression,
- AI safety,
- scientific computing and scientific discovery,
- causal inference,
- foundation models,
- lifelong and continual learning

**Area 2 (New!): Applications of Probabilistic and/or Bayesian Methods to Healthcare and Climate Change.** 
For this new focus area, we aim to foster stronger communication and collaboration between researchers developing probabilistic/Bayesian machine learning methodology and researchers focused primarily on real-world applications. 
As such, in this area, novel methodology/theory is **not** an evaluation criterion. 
Instead, we encourage submissions that:

- Propose **thoughtful, rigorous** uses of probabilistic/Bayesian models or inference, with clear **empirical and scientific evidence for why** the chosen methodology is well-aligned with the downstream task.
- Use probabilistic/Bayesian methods to **advance scientific understanding**, for example, by **carefully integrating** domain expertise, physical constraints, or mechanistic knowledge into the modeling and inference pipeline.
- Tackle applications where problems **cannot (or should not) be addressed solely by scaling up data and deep learning models**, such as data-sparse regimes, high-stakes decision making, causal reasoning, or settings with strict interpretability, safety, or governance requirements.


## Key Dates

<h3 id="proceeding-track-dates">Proceedings Track</h3>

- **Submission deadline:** 20 March 2026 (11:59 PM AoE)
- **Reviews released:** 17 April 2026
- **Author rebuttal due:** 24 April 2026 (11:59 PM AoE)
- **Acceptance notification:** 8 May 2026
- **Camera-ready for accepted submissions:** 19 June 2026
- **Symposium date:** 5 July 2026

<h3 id="workshop-track-dates">Workshop Track</h3>

- **Submission deadline:** 20 March 2026 (11:59 PM AoE)
- **Acceptance notification:** 8 May 2026
- **Camera-ready for accepted submissions:** 19 June 2026
- **Symposium date:** 5 July 2026

<h3 id="fast-track-dates">Fast Track</h3>

- **Submission deadline:** 20 March 2026 (11:59 PM AoE)
- **Acceptance notification:** 1 April 2026

## Paper Submission

We have three submission tracks:

- a [Proceedings Track](#proceedings-track), for **full research papers** of up to 9 content pages,
- a [Workshop Track](#workshop-track), for **extended abstracts** of 3-5 content pages, and
- a [Fast Track](#fast-track), for **recently published papers**.

Acknowledgements, references, and appendices do not contribute to the page limits.

### Proceedings Track

The proceedings track is ProbML’s archival research paper track.
Submissions will undergo a rigorous double-blind open peer-review process.
All accepted papers will be presented at the symposium as contributed talks and/or posters and will all be published in the proceedings.

A submission is no longer than 9 pages in PDF format using the ProbML LaTeX template ([**template**](https://github.com/wiseodd/probml-style-file/releases/download/2026/probml-latex-template.zip)).
Author names must be anonymized and may not contain any information that can break anonymity.
References may extend beyond the page limit.
Submissions may include a supplement, but reviewers are not required to read any supplementary material.
Preprints must not be explicitly identified as ProbML submissions, and we recommend that authors avoid advertising the material during the review process.

The review process will be a double-blind open review.
After the initial reviews are released (17 April 2026), there will be one (1) week of author-reviewer discussion.
The final decisions will then be released on 8 May 2026.

Proceedings track papers published at ProbML will be indexed in the Proceedings of Machine Learning Research through the Journal of Machine Learning Research (PMLR) under the series name Symposium on Probabilistic Machine Learning.

**Dual submission policy:**
Submitted manuscripts should not have been previously published in the proceedings of a conference or in a journal, nor should they be under consideration for publication at another conference or journal at any point during the ProbML review process.
Extended abstracts and/or preprints (such as ArXiv) in non-archival venues will not be considered concurrent submissions.

To submit proceedings track papers, please use the [OpenReview submission link](https://openreview.net/group?id=ProbML.cc/2026/Proceedings_Track) (opening soon).

### Workshop Track

A workshop track submission should take the form of an extended abstract of 3–5 pages in PDF format.
Submissions may use the ProbML LaTeX template ([**template**](https://github.com/wiseodd/probml-style-file/releases/download/2026/probml-latex-template.zip)) or the format of any other workshop, so long as the length is not more than 5 content pages.

The review process will be double-blind. Author names need to be anonymized, and references may extend beyond the 5-page limit. Submissions may include a supplement/appendix, but reviewers are not required to read any supplementary material. Final decisions and reviews will be released on 8 May 2026.

All accepted submissions will be presented in person as posters.
Note that the workshop track is non-archival.

**Dual submission policy:** If a paper has previously appeared in a journal, workshop, or conference, it should be extended to be accepted at ProbML 2026.
If a paper is currently under review, it can still be submitted to the ProbML workshop track without extension.

To submit workshop track papers, please use the [OpenReview submission link](https://openreview.net/group?id=ProbML.cc/2026/Workshop_Track).

### Fast Track

We also invite researchers to present papers on the development, analysis, or application of probabilistic machine learning that have previously been accepted at major machine learning conferences and journals post AABI 2025 (the former name of ProbML): ICML 2025, NeurIPS 2025, ICLR 2026, AISTATS 2026, UAI 2026, ICML 2026, as well as JMLR and TMLR.
These papers should be formatted according to the camera-ready standards of their respective venues.
Author names do not need to be anonymized. 
ProbML Fast Track is non-archival and does not have proceedings to avoid conflict with other venues' double submission policies.

Papers accepted within this modality will be presented in person as posters. These papers will not appear on the ProbML website.

To submit fast-track papers, please use [this submission link](https://forms.gle/ExkdRLbMYG3Sybwt7).

Papers must be submitted by 20 March 2026. Acceptance notifications will be sent on 1 April 2026.


## Areas of Focus

Across all three tracks, we encourage contributions in **two primary areas of focus**, described below. 

### Area 1: Probabilistic and/or Bayesian ML Methods 

We welcome methodological and theoretical contributions in advancing the foundations of probabilistic machine learning, probabilistic and (approximate) Bayesian inference, Bayesian statistics, and decision-making under uncertainty. 
We also encourage work exploring connections between these fields and adjacent areas such as deep learning, natural language processing, active learning, reinforcement learning, compression, AI safety, scientific computing, and causal inference.
Relevant topics include, but are not limited to:

- **Probabilistic and approximate inference:** variational inference, Monte Carlo methods, expectation propagation, Laplace approximations, normalizing flows.
- **Model development:** Bayesian neural networks, Gaussian processes, probabilistic graphical models, state-space models, hierarchical models, and structured probabilistic models.
- **Uncertainty quantification:** calibration, out-of-distribution detection, uncertainty decomposition, conformal prediction.
- **Theory:** convergence guarantees, approximation quality, PAC-Bayesian theory.
- **Decision-making under uncertainty:** Bayesian optimization, active learning, experimental design, multi-armed bandits, and distributional/Bayesian reinforcement learning, planning and search under uncertainty.
- **Scalability and efficiency:** amortized methods, federated learning.
- **Connections to modern ML:** Bayesian deep learning, uncertainty in foundation models, and uncertainty-aware generative AI.

Submissions in this area will be evaluated on:

- **Methodological or theoretical contribution:** What new inference methods, modeling frameworks, or theoretical insights does the work provide? How does it advance current knowledge or the state of the art?
- **Technical rigor:** Are the methods theoretically grounded? Are claims supported by proofs, formal analysis, or rigorous numerical validation?
- **Empirical validation:** When applicable, how is the method evaluated? Are experiments well-designed with appropriate baselines, metrics, and datasets?
- **Clarity and reproducibility:** Is the work clearly presented with sufficient detail for reproducibility?


### Area 2 (New!): Applications of Probabilistic and/or Bayesian Methods to Healthcare and Climate Change

For this new focus area, we aim to foster stronger communication and collaboration between researchers developing probabilistic/Bayesian machine learning methodology and researchers focused primarily on real-world applications. As such, in this area, novel methodology/theory is **not** an evaluation criterion (though it is always welcome). Instead, we encourage submissions that:
- Propose **thoughtful, rigorous** uses of probabilistic/Bayesian models or inference, with clear **empirical and scientific evidence for why** the chosen methodology is well-aligned with the downstream task.
- Use probabilistic/Bayesian methods to **advance scientific understanding**, for example, by **carefully integrating** domain expertise, physical constraints, or mechanistic knowledge into the modeling and inference pipeline.
- Tackle applications where problems **cannot (or should not) be addressed solely by scaling up data and deep learning models**, such as data-sparse regimes, high-stakes decision making, causal reasoning, or settings with strict interpretability, safety, or governance requirements.

We welcome a broad range of application-driven contributions in this track, including but not limited to:
- **Clinical and public health applications**, such as diagnosis and prognosis under uncertainty, individualized treatment recommendations, clinical trial design and monitoring, health policy evaluation, infectious disease modeling, and resource allocation in healthcare systems.
- **Climate and environmental applications**, such as climate model calibration and emulation, extreme event modeling, uncertainty quantification in climate and weather projections, climate-informed decision support, environmental risk assessment, and integration of physical and data-driven models.
- **Decision-making under uncertainty**, including Bayesian decision analysis, optimal experimental design, adaptive policies, and decision support tools for practitioners and policymakers.
- **Model critique, validation, and robustness in real systems**, focusing on model misspecification, distributional shifts, reliability in deployment, and principled communication of uncertainty to stakeholders.

Submissions in this area will be evaluated on:

- **The real-world problem and its impact:** Why is this problem important for healthcare or climate change? Who are the stakeholders, and what decisions or outcomes does the work aim to influence?
- **The role of probabilistic/Bayesian methods:** Why are probabilistic/Bayesian approaches particularly well-suited (or necessary) for this application? How does the approach leverage uncertainty, prior knowledge, causal structure, or domain constraints?
- **Empirical and scientific validation:** How is the proposed approach evaluated (e.g., predictive performance, calibration, decision quality, robustness, interpretability)?
- What **evidence** is provided that the method improves understanding, decisions, or outcomes relative to existing practice?
- When applicable, **practical considerations and deployment**: how does the work engage with real data, real users, or real systems? What are the limitations, assumptions, and open challenges for practical deployment?
